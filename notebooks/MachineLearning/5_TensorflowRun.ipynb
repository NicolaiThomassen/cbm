{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Run\n",
    "\n",
    "This is the core tensorflow run. It sets up the model by applying a DNN to the training data and then predict the class labels for the test data.\n",
    "\n",
    "This module may get stuck when running more than once. The model section will throw an IndexError: list index out of range. \n",
    "Restart the kernel in these cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "\n",
    "# Load CSV file, indicate that the last column represents labels\n",
    "from tflearn.data_utils import load_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conect to the database\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the table names\n",
    "parcels_table = \"aoi2020\"\n",
    "\n",
    "# Set the folder to store the data\n",
    "data_folder = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tflearn.init_graph(gpu_memory_fraction=0.0)\n",
    "\n",
    "nclass = 11\n",
    "nepoch = 50\n",
    "nrun = 0\n",
    "\n",
    "data, labels = load_csv(f'{data_}{parcels_table}_train_{nrun}.csv', target_column=-1, \n",
    "                        categorical_labels=True, n_classes=nclass)\n",
    "\n",
    "test_data, test_labels = load_csv(f'{data_}{parcels_table}_test_{nrun}.csv', target_column=-1,\n",
    "                        categorical_labels=True, n_classes=nclass)\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(profiles, columns_to_delete):\n",
    "    # Sort by descending id and delete columns\n",
    "    for column_to_delete in sorted(columns_to_delete, reverse=True):\n",
    "        [profile.pop(column_to_delete) for profile in profiles]\n",
    "    \n",
    "    return np.array(profiles, dtype=np.float32)\n",
    "\n",
    "# Ignore 'pid' \n",
    "to_ignore=[0,1]\n",
    "\n",
    "# Preprocess data\n",
    "# If the next statement throws a string to float32 conversion error, you may have NA() in the data. Remove!\n",
    "data = preprocess(data, to_ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 58549  | total loss: \u001b[1m\u001b[32m0.95439\u001b[0m\u001b[0m | time: 2.429s\n",
      "| Adam | epoch: 050 | loss: 0.95439 - acc: 0.6407 -- iter: 37440/37442\n",
      "Training Step: 58550  | total loss: \u001b[1m\u001b[32m0.98672\u001b[0m\u001b[0m | time: 2.431s\n",
      "| Adam | epoch: 050 | loss: 0.98672 - acc: 0.6266 -- iter: 37442/37442\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Build neural network\n",
    "net = tflearn.input_data(shape=[None, len(data[0])])\n",
    "\n",
    "net = tflearn.fully_connected(net, 32)\n",
    "net = tflearn.fully_connected(net, 32)\n",
    "#net = tflearn.fully_connected(net, 32)\n",
    "net = tflearn.fully_connected(net, nclass, activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "# Define model\n",
    "model = tflearn.DNN(net)\n",
    "# Start training (apply gradient descent algorithm)\n",
    "model.fit(data, labels, n_epoch=nepoch, batch_size=32, show_metric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the trained model to predict the class label for the test data\n",
    "fw = open(f\"{data_}{parcels_table}_predictions_{nrun}.csv\", 'w')\n",
    "fw.write(\"id,class\")\n",
    "for i in range(nclass):\n",
    "    fw.write(f\",prob{i}\")\n",
    "fw.write('\\n')\n",
    "\n",
    "# Check predictions for the samples not used in training\n",
    "for i in range(len(test_data)):\n",
    "    sample = test_data[i][2:]\n",
    "    slabel = test_labels[i].tolist().index(1)\n",
    "    #print(labels[i])\n",
    "    pred = model.predict([sample])\n",
    "    fw.write(f\"{test_data[i][1]},{str(slabel)}\")\n",
    "    for i in range(nclass):\n",
    "        fw.write(\",{:6.2f}\".format(100*pred[0][i]))\n",
    "    fw.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
